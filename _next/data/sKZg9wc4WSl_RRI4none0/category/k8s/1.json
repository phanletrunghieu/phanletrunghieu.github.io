{"pageProps":{"slug":"k8s","categories":["ReactJS","K8s","Docker","GI/CD","Tip","Gitlab","Microservice"],"allBlogs":[{"frontmatter":{"author":"Hieu Phan","date":"2021-03-01T07:00:00.000Z","image":"/images/10-deploy-multi-region-applications-with-k8s/cover.jpg","title":"Deploy multi-region applications with k8s","readDuration":"30 min","categories":["K8s"]},"markdownBody":"\n## 1. Run 2 K8S clusters locally for practicing\n\nCreate 2 clusters with 1 master for each cluster. Image clusters put in different regions.\n\nSee [this post](/post/9-run-multi-node-k8s-cluster-locally).\n\n## 2. Solution\n\nIn my case, I use MariaDB with `replication` architecture.\n\n![Solution](/images/10-deploy-multi-region-applications-with-k8s/1-solution.jpg)\n\nI use `bitnami/mariadb` 9.3.4 chart.\n\nI need run mariadb with primary & secondary in different nodes, but `bitnami/mariadb` allow run 1 primary and many secondary nodes. So I need run some customization.\n\n## 3. Customize `bitnami/mariadb` chart\n\n3.1. Add primary.enabled to `values.yaml`\n\n```yaml\nprimary:\n  enabled: true\n```\n\n3.2. Add condition `.Values.primary.enabled` to all file in `templates/primary`\n\n3.3. Add master's information to secondary in `values.yaml`.\n\n```yaml\nsecondary:\n  master:\n    host:\n    port:\n```\n\n3.4. Update env in `templates/secondary/statefulset.yaml`\n\n```yaml\nenv:\n  - name: MARIADB_MASTER_HOST\n    value: {{ default (include \"mariadb.primary.fullname\" .) .Values.secondary.master.host }}\n  - name: MARIADB_MASTER_PORT_NUMBER\n    value: {{ default .Values.primary.service.port .Values.secondary.master.port | quote }}\n```\n\nSee my final custom chart on [Github](https://github.com/phanletrunghieu/multi-region-k8s)\n\n## 4. Deploy\n\nSwitch `kubectl` to cluster 1 and run\n\n```yaml\nhelm -n app  upgrade --install app . --create-namespace -f values.region-1.yaml\n```\n\nSwitch `kubectl` to cluster 2 and run\n```yaml\nhelm -n app  upgrade --install app . --create-namespace -f values.region-2.yaml\n```","slug":"10-deploy-multi-region-applications-with-k8s"},{"frontmatter":{"author":"Hieu Phan","date":"2021-02-25T07:00:00.000Z","image":"/images/9-run-multi-node-k8s-cluster-locally/cover.jpg","title":"Run multi-node kubernetes cluster locally within 15 minutes","readDuration":"15 min","categories":["K8s"]},"markdownBody":"\n## 1. Prepare tools\n\n- multipass 1.6.2: `brew install --cask multipass`\n- virtualbox 6.1.18: `brew install --cask virtualbox`\n\n> Note: You can install tools with other tools.\n\n## 2. Create 2 VMs\n\nCreate 2 nodes Ubuntu 20.04, 1G RAM, 1 CPU, 8GB disk.\n\n```bash\nmultipass launch -vvv -n node-1 -m 1G -d 8GB -c 1 20.04\nmultipass launch -vvv -n node-2 -m 1G -d 8GB -c 1 20.04\n```\n\nCheck in VirtualBox: `sudo VirtualBox`\n> Note: Open VirtualBox with sudo\n\n![Nodes in the cluster](/images/9-run-multi-node-k8s-cluster-locally/1-nodes-in-cluster.png)\n\n## 3. Configure the network\n\nBecause 2 VMs use network NAT, it has no a special ip. So we need to create 2 new networks: Host-only (nodes will communicate to each other with this network), NAT network (to allow nodes be able to access the internet) and disable the current NAT.\n\n\n3.1. In **VirtualBox**, open **Preferences**, create a new NatNetwork and enable DHCP\n\n![Create NAT network](/images/9-run-multi-node-k8s-cluster-locally/2-create-nat-network.png)\n\n![NAT network with DHCP](/images/9-run-multi-node-k8s-cluster-locally/3-nat-network-dhcp.png)\n\n3.2. Shutdown nodes\n\n![Shutdown nodes](/images/9-run-multi-node-k8s-cluster-locally/4-shutdown-nodes.png)\n\n3.3. Add new networks\n\n![Add new networks](/images/9-run-multi-node-k8s-cluster-locally/5-add-new-network-1.png)\n\n![Add new networks](/images/9-run-multi-node-k8s-cluster-locally/5-add-new-network-2.png)\n\n3.4. Start nodes\n\n![Start nodes](/images/9-run-multi-node-k8s-cluster-locally/6-start-nodes.png)\n\n3.5. If the `~/.ssh/id_rsa` file is not exist, generate a pair of ssh keys.\n\n```bash\nssh-keygen -C \"hieu@deptrai\"\ncat ~/.ssh/id_rsa.pub\n```\n\n3.6. SSH to node 1:\n\n```bash\nmultipass shell node-1\n```\n\n3.7. Write your ssh public key to node-1\n```bash\necho \"your_ssh_public_key\" | tee -a ~/.ssh/authorized_keys\n```\n\nReplace `your_ssh_public_key` with `~/.ssh/id_rsa.pub` file's content.\n\nExample:\n\n```bash\necho \"ssh-rsa AAAAB3NzaC1yc2E..... hieu@deptrai\" | tee -a ~/.ssh/authorized_keys\n```\n\n3.8. Enable 2 networks that we enabled\n\n```bash\nip link | grep DOWN\n```\n\nThey are usually `enp0s8` and `enp0s9`\n![Start nodes](/images/9-run-multi-node-k8s-cluster-locally/7-network-down.png)\n\nRun this command with `sudo`. Notice `enp0s8` and `enp0s9`.\n\n```bash\nsudo bash -c \"cat > /etc/netplan/60-bridge.yaml\" <<EOF\nnetwork:\n  ethernets:\n    enp0s8:\n      dhcp4: true\n      dhcp4-overrides:\n        route-metric: 200\n    enp0s9:\n      dhcp4: true\n      dhcp4-overrides:\n        route-metric: 200\n  version: 2\nEOF\n```\n```bash\nsudo netplan apply\nip addr show\n```\n\nThe `enp0s9`'s ip is `192.168.56.108`\n\n3.9. Exit ssh:\n```\nexit\n```\n\n3.10. Shutdown node-1 -> disable `NAT` at `Adapter 1` -> Start node-1\n\n![Disable network at adapter 1](/images/9-run-multi-node-k8s-cluster-locally/8-disable-network-adapter-1.png)\n\n3.11. Repeat steps `3.6`-`3.10` with `node-2`\n\nFinally, we have IPs:\n- Node-1: 192.168.56.108\n- Node-2: 192.168.56.109\n\n## 4. Setup a k8s cluster\n\n4.1. Install k3sup\n\n```bash\ncurl -sLS https://get.k3sup.dev | sh\nsudo install k3sup /usr/local/bin/\n```\n\n4.2. Install Kubernetes in `node-1` with `master` role.\n\n```bash\nk3sup install --ip 192.168.56.108 --user ubuntu --context k3s-1 --k3s-version v1.19.8+k3s1\n```\n\n4.3. Install Kubernetes in `node-2` with `worker` role.\n\n```bash\nk3sup join --ip 192.168.56.109 --server-ip 192.168.56.108 --user ubuntu --k3s-version v1.19.8+k3s1\n```\n\nIt will create `kubeconfig` file in your current directory.\n\n## 5. Test\n\n```bash\nexport KUBECONFIG=/Users/hieudeptrai/kubeconfig\nkubectl get node -o wide\n```\n\nDone!","slug":"9-run-multi-node-k8s-cluster-locally"},{"frontmatter":{"author":"Hieu Phan","date":"2020-08-30T06:24:00.000Z","image":"/images/7-install-k3s-in-digitalocean/cover.jpg","title":"Setup K3s on Digitalocean","readDuration":"10 min","categories":["K8s"]},"markdownBody":"\n## 1. Create a Droplet\n\n![Create a Droplet](/images/7-install-k3s-in-digitalocean/1-create-a-droplet.png)\n\nResult:\n\n![Result Droplet](/images/7-install-k3s-in-digitalocean/2-result-droplet.jpg)\n\nTry to ssh to droplet.\n\n```bash\nssh root@123.456.789.012\n```\n\nInstall somethings:\n\n```bash\napt install curl\n```\n\nIf success, go to step 2.\n\n## 2. Install `k3sup` on your computer\n\n```bash\ncurl -sLS https://get.k3sup.dev | sh\n```\n\n## 3. Install k3s\n\n```bash\nk3sup install --ip 123.456.789.012 --user root\n```\n\n![Result 3-k3sup](/images/7-install-k3s-in-digitalocean/3-k3sup.png)\n\n## 4. Test\n\nAfter installing successfully, we have `kubeconfig` file.\n\n```bash\nexport KUBECONFIG=/Users/hieudeptrai/kubeconfig\nkubectl get node -o wide\n```\n\nDone!","slug":"7-install-k3s-in-digitalocean"}],"title":"Hlog - Code for fun","description":"Cùng nhau chia sẻ kinh nghiệm, mò mẫm kiến thức mới","currentPage":"1","totalPage":1},"__N_SSG":true}